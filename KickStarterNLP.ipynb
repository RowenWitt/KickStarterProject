{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67ae0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle, json\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing, opening pickled array, size brought down from 20.4 GBs to .5 GBs pre-pickling\n",
    "with open('PreProcessing/kickXY.pkl', 'rb') as fp:\n",
    "\tbase = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df3bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rowenwitt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Key for array column names\n",
    "# key = [0'unid', 1'timeline', 2'goalUSD', 3'category', 4'text', 5'state']\n",
    "\n",
    "# Turning array input from scraped data into dataframe\n",
    "bigDF = pd.DataFrame(data=base)\n",
    "\n",
    "# Splitting category 'slug' into category & subcategory\n",
    "bigDF[3] = bigDF[3].str.split('/', n=1)\n",
    "bigDF[6] = [bigDF[3][i][-1] for i in range(len(bigDF))]\n",
    "bigDF[3] = [bigDF[3][i][0] for i in range(len(bigDF))]\n",
    "\n",
    "# Dropping 'live', 'canceled', 'suspended' records and removing dupes (3.6M->221K)\n",
    "states = ['live', 'canceled', 'suspended']\n",
    "for i in range(len(states)):\n",
    "    bigDF.drop(bigDF[bigDF[5] == states[i]].index, inplace=True)\n",
    "\n",
    "bigDFunique = bigDF.drop_duplicates(keep='last')\n",
    "\n",
    "# Dropping unique_id column post dupe-removal\n",
    "bigDFunique.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned, de-duped, state-simplified csv (3.6M -> 221K)\n",
    "bigDFunique.to_csv('cleanKick.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDFunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88582350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-e6fc0a584793>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bigDFunique[3] = LeCat.transform(bigDFunique[3])\n",
      "<ipython-input-5-e6fc0a584793>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bigDFunique[6] = LeSubCat.transform(bigDFunique[6])\n",
      "<ipython-input-5-e6fc0a584793>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bigDFunique[5] = LeState.transform(bigDFunique[5])\n"
     ]
    }
   ],
   "source": [
    "# Label encode category, state, subCategory\n",
    "LeCat = LabelEncoder()\n",
    "LeSubCat = LabelEncoder()\n",
    "LeState = LabelEncoder()\n",
    "\n",
    "# Fit encoders on respective columns\n",
    "LeCat.fit(bigDFunique[3])\n",
    "LeSubCat.fit(bigDFunique[6])\n",
    "LeState.fit(bigDFunique[5])\n",
    "\n",
    "# Apply encodings to columns\n",
    "bigDFunique[3] = LeCat.transform(bigDFunique[3])\n",
    "bigDFunique[6] = LeSubCat.transform(bigDFunique[6])\n",
    "bigDFunique[5] = LeState.transform(bigDFunique[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d380ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict maps\n",
    "def ones(imp):\n",
    "    out = []\n",
    "    for i in range(len(imp)):\n",
    "        out.append(i)\n",
    "    \n",
    "    dmap = dict(zip(out, imp))\n",
    "    return dmap\n",
    "\n",
    "StateMap = ones(LeState.classes_)\n",
    "CatMap = ones(LeCat.classes_)\n",
    "SubCatMap = ones(LeSubCat.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b010dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubCatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bccbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Tokenizer\n",
    "tok = Tokenizer()\n",
    "\n",
    "# Fitting tokenizer on df text array\n",
    "tok.fit_on_texts(texts=bigDFunique[4])\n",
    "\n",
    "# Getting word index from tokenizer\n",
    "dex = tok.word_index\n",
    "\n",
    "# Keep work index to 1000 words\n",
    "tok.num_words = 1000\n",
    "\n",
    "# Creating sequences from df text array\n",
    "seqs = tok.texts_to_sequences(bigDFunique[4])\n",
    "max_features = len(dex.values()) + 1\n",
    "maxlen = 43\n",
    "\n",
    "# Saving tokenizer to pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Padding sequence length\n",
    "bigX = sequence.pad_sequences(seqs, maxlen)\n",
    "\n",
    "# Creating list of reconstructed text\n",
    "recons = tok.sequences_to_texts(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e0acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f749c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211038, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigDFunique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2be7ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b0ee71e790d5>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bigDFunique[j] = [bigX[i][f] for i in range(len(bigDFunique))]\n"
     ]
    }
   ],
   "source": [
    "# Giving text encodings (bigX) own column 7-49\n",
    "for j in range(7, (50)):\n",
    "    f = j-7\n",
    "    bigDFunique[j] = [bigX[i][f] for i in range(len(bigDFunique))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b071d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping out column 4 (unencoded text), re-naming columns, renaming df to df\n",
    "df = bigDFunique.drop(columns=[4])\n",
    "\n",
    "newColumns = [i for i in range(48)]\n",
    "df.columns = newColumns\n",
    "\n",
    "# Splitting into X and Y (4 = success/failure)\n",
    "target = 3\n",
    "X = df.drop(columns=target)\n",
    "Y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a05547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21294</th>\n",
       "      <td>30</td>\n",
       "      <td>7895.704536</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21976</th>\n",
       "      <td>24</td>\n",
       "      <td>4008.273100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>536</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>85</td>\n",
       "      <td>330</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29021</th>\n",
       "      <td>60</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>650</td>\n",
       "      <td>198</td>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44904</th>\n",
       "      <td>31</td>\n",
       "      <td>1558.756540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>237</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>76</td>\n",
       "      <td>113</td>\n",
       "      <td>635</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45339</th>\n",
       "      <td>31</td>\n",
       "      <td>5623.373450</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>383</td>\n",
       "      <td>36</td>\n",
       "      <td>262</td>\n",
       "      <td>171</td>\n",
       "      <td>133</td>\n",
       "      <td>814</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658378</th>\n",
       "      <td>17</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>531</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658379</th>\n",
       "      <td>30</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>239</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658380</th>\n",
       "      <td>20</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>634</td>\n",
       "      <td>43</td>\n",
       "      <td>745</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>910</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658381</th>\n",
       "      <td>30</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>648</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>291</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658382</th>\n",
       "      <td>30</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>880</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>187</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211038 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0             1   2   3    4   5   6   7   8   9   ...   38   39  \\\n",
       "21294    30   7895.704536  12   1   82   0   0   0   0   0  ...    0    0   \n",
       "21976    24   4008.273100   1   1   66   0   0   0   0   0  ...  199   24   \n",
       "29021    60  11000.000000   1   0   66   0   0   0   0   0  ...   22  650   \n",
       "44904    31   1558.756540   1   1    6   0   0   0   0   0  ...  146  237   \n",
       "45339    31   5623.373450   8   1  106   0   0   0   0   0  ...    0    0   \n",
       "...      ..           ...  ..  ..  ...  ..  ..  ..  ..  ..  ...  ...  ...   \n",
       "3658378  17    600.000000   0   0   28   0   0   0   0   0  ...    0  119   \n",
       "3658379  30  10000.000000  12   0  159   0   0   0   0   0  ...    4  534   \n",
       "3658380  20   3100.000000   0   1   70   0   0   0   0   0  ...  634   43   \n",
       "3658381  30   5000.000000  12   0   15   0   0   0   0   0  ...   41  648   \n",
       "3658382  30   1970.000000  11   0    4   0   0   0   0   0  ...  880    4   \n",
       "\n",
       "          40   41   42   43   44   45   46   47  \n",
       "21294      0    0    0    0    0    0    0    0  \n",
       "21976     51  536    3    3   27   85  330  496  \n",
       "29021    198  630    1  370   63    3  107    2  \n",
       "44904      5    2  266   76  113  635  620    2  \n",
       "45339      2  383   36  262  171  133  814    3  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "3658378   22   54   50  531   27    6    2  408  \n",
       "3658379   61    6  239   35   12   42   28  759  \n",
       "3658380  745    5    2  240    2  910    3    2  \n",
       "3658381    6    2    5    3    2    3  291    5  \n",
       "3658382  103  111  110  187    7    1  227   16  \n",
       "\n",
       "[211038 rows x 48 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c147fe79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1a0230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((147726, 47), (147726,)), ((63312, 47), (63312,)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating X,Y Train and X,Y Validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "((X_train.shape, y_train.shape),(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c763f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train to numpy array\n",
    "arr = X_train.to_numpy()\n",
    "# Reshape numpy array into 3D tensor\n",
    "tarr = arr.reshape(147726, 47, 1)\n",
    "# Convert ints to floats\n",
    "X_train = np.asarray(tarr).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "\n",
    "# Convert X_test to numpy array\n",
    "arr = X_test.to_numpy()\n",
    "# Reshape numpy array into 3D tensor\n",
    "varr = arr.reshape(63312, 47, 1)\n",
    "# Convert ints to floats\n",
    "X_test = np.asarray(varr).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd873f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b91a7c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((147726, 47, 1), (147726,)), ((63312, 47, 1), (63312,)))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X_train.shape, y_train.shape), (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4e0d573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131099"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a1b1e80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.8000000e+01],\n",
       "        [1.5000000e+03],\n",
       "        [1.0000000e+01],\n",
       "        ...,\n",
       "        [1.0000000e+01],\n",
       "        [4.4300000e+02],\n",
       "        [3.2000000e+01]],\n",
       "\n",
       "       [[4.8000000e+01],\n",
       "        [3.3951188e+04],\n",
       "        [8.0000000e+00],\n",
       "        ...,\n",
       "        [3.2000000e+02],\n",
       "        [3.8000000e+01],\n",
       "        [6.1000000e+01]],\n",
       "\n",
       "       [[3.0000000e+01],\n",
       "        [1.0000000e+03],\n",
       "        [7.0000000e+00],\n",
       "        ...,\n",
       "        [7.6400000e+02],\n",
       "        [1.0300000e+02],\n",
       "        [3.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4.0000000e+01],\n",
       "        [1.5000000e+04],\n",
       "        [7.0000000e+00],\n",
       "        ...,\n",
       "        [8.5400000e+02],\n",
       "        [2.2000000e+01],\n",
       "        [6.8100000e+02]],\n",
       "\n",
       "       [[4.4000000e+01],\n",
       "        [5.0000000e+03],\n",
       "        [4.0000000e+00],\n",
       "        ...,\n",
       "        [3.0000000e+00],\n",
       "        [5.0000000e+00],\n",
       "        [8.9800000e+02]],\n",
       "\n",
       "       [[3.0000000e+01],\n",
       "        [2.3473076e+03],\n",
       "        [2.0000000e+00],\n",
       "        ...,\n",
       "        [3.8000000e+01],\n",
       "        [2.0000000e+00],\n",
       "        [8.7000000e+01]]], dtype=float32)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "795f12fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n"
     ]
    }
   ],
   "source": [
    "print('building model')\n",
    "maxlen = 43\n",
    "dim = len(dex)\n",
    "model = Sequential()\n",
    "\n",
    "\"\"\" Changes made\n",
    "- Try dropping out unid > Holy shit it broke the model, was it keying on unid?\n",
    "    Nope, I'm an idiot and it frameshifted one to left (durrrr)\n",
    "- Added second LSTM layer, has not really impacted accuracy\n",
    "- Added dense layer\n",
    "\"\"\"\n",
    "\n",
    "# Try embeddings (will it work if only 43/49 columns are encoded words?)\n",
    "\n",
    "# Try normalizing inputs (just words? everything individually?)\n",
    "\n",
    "# Try playing with layers (Add'l dense layer?  Add'l LSTM layer?)\n",
    "\n",
    "# model.add(Embedding(input_dim=15000,\n",
    "# \t\t\t\t\tembeddings_initializer=\"uniform\", output_dim=256))\n",
    "\n",
    "model.add(LSTM(64, input_shape=(47, 1), dropout=0.1, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(64, input_shape=(47, 1), return_sequences=True))\n",
    "\n",
    "model.add(LSTM(64, input_shape=(47, 1), return_sequences=False))\n",
    "\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ba1ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "52b701db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "\n",
    "# # with a Sequential model\n",
    "# get_3rd_layer_output = K.function([model.layers[3].input],\n",
    "#                                   [model.layers[0].output])\n",
    "# layer_output = get_3rd_layer_output([0])[0]\n",
    "\n",
    "# print(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "404ca407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "Epoch 1/100\n",
      "1155/1155 [==============================] - 102s 85ms/step - loss: 0.6591 - accuracy: 0.6138 - val_loss: 0.6495 - val_accuracy: 0.6288\n",
      "Epoch 2/100\n",
      "1155/1155 [==============================] - 97s 84ms/step - loss: 0.6439 - accuracy: 0.6291 - val_loss: 0.6347 - val_accuracy: 0.6412\n",
      "Epoch 3/100\n",
      "1155/1155 [==============================] - 102s 88ms/step - loss: 0.6343 - accuracy: 0.6368 - val_loss: 0.6213 - val_accuracy: 0.6503\n",
      "Epoch 4/100\n",
      "1155/1155 [==============================] - 113s 98ms/step - loss: 0.6170 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6522\n",
      "Epoch 5/100\n",
      "1155/1155 [==============================] - 111s 96ms/step - loss: 0.6004 - accuracy: 0.6667 - val_loss: 0.6585 - val_accuracy: 0.6594\n",
      "Epoch 6/100\n",
      " 777/1155 [===================>..........] - ETA: 34s - loss: 0.5937 - accuracy: 0.6718"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-c3719f363547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(tarr, y_train,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"training\")\n",
    "history = model.fit(tarr, y_train,\n",
    "\t\t\t\t   validation_data=(varr, y_test),\n",
    "\t\t\t\t   batch_size=128,\n",
    "\t\t\t\t   epochs=100,\n",
    "\t\t\t\t   verbose=1,\n",
    "                   workers=10)\n",
    "\n",
    "print(history)\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bf68a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save first model (get a point on the board!)\n",
    "model.save('models/model2')\n",
    "print('saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "05e0828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Convert model to tflite model (it can't be that simple)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('models')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Resave model\n",
    "with open('model1.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will take forever to run, accuracy is so-so for 3-category class\n",
    "# Options are\n",
    "#    1. Sample data set, 3,600,000 is too many (weak)\n",
    "#    2. Set up EC2 instance, pay like 10 dollars/hour (cool, difficult)\n",
    "#    3. Increase batch-size to the 10k range (dumb?)\n",
    "#    4. Decrease validation size to 1/5\n",
    "#                Test set size = 1,830,912 ... 1/5 = 366,182.4\n",
    "# Blurb dataset is 150Char, Descrip dataset is 3,500Char\n",
    "# Will this impact training time?  Maybe not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6aa272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
